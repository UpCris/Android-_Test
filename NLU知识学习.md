## 对话系统的组成
1.	语音识别ASR(Automated Speech Recognition): 将原始的语音信号 ---> 文本信息
2.	自然语言理解NLU(Natural-language Understanding): 将识别打出来的文本信息 ---> 机器可以理解的、结构化的、完整的语义表示
3.	对话管理DM(Dialog Management):  基于对话的状态判断系统应该采取什么动作，这里的动作可理解为机器需要表达什么意思, 使机器人能够存储对话期间出现但未立即采取行动的用户意图
4.	自然语言生成NLG(Natural-lanauge Generation):   从数据集中, 将系统动作 ---> 自然语言文本
5.	语音合成TTS(Text-to-speech):  自然语言文本 ---> 语音(给用户)
 问答典型流程
### 分词
通过分词模型，将一个文字序列切分成一个个词或短语
中文分词模型：jieba分词、pyltp分词、sentencepiece分词、bert tokenizer分词
#### 分词算法的两大分类 
1.	基于词典的规则分词方法
2.	基于统计的机器学习分词方法
#### 中文分词的难点
1.	 分词标准：人名如何分词
2.	 歧义：
- 组合型歧义：分词是有不同的粒度的，某个词条中的一部分也可以切分为一个独立的词条（中华人民共和国）
- 交集型歧义：“郑州天和服装厂”，“天和”or“和服”
- 真歧义：本身的语法和语义都没有问题，即便采用人工切分也会产生同样的歧义，只有通过上下文的语义环境才能给出正确的切分结果。“美国会通过对台售武法案”， “美国/会/通过对台售武法案”or “美/国会/通过对台售武法案”
3.	 新词: 未被词典收录的词
### 词性标注
分词模型将用户输入的文字序列变成”词语序列”后，就需要通过标注模型来标注这些词语的词性：即确定它们在这句话中是名词、动词还是代词等等.
词性标注基本可以照搬分词的工作: 
在汉语中，大多数词语只有一个词性，或者出现频次最高的词性远远高于第二位的词性。据说单纯选取最高频词性，就能实现80%准确率的中文词性标注程序。
命名体识别NER(Named Entity Recognition):
文本中具有特定意义或者指代性强的实体, 包括三大类(实体类、时间类、数字类)、七小类(人名、机构名、地名、时间、日期、货币、百分比)命名实体
### 	特征提取、分类检索: 
将用户输入的文字序列变成向量的过程
根据分词和词性标注的结果，可以根据某种规则来提取文字序列的若干特征，组成一个向量；向量的每个分量则描述了文字序列的一种特征。文字序列变成了机器擅长处理的向量形式后，即可进行后续的分类与检索
- 以分词组合作为词向量
- 以语义信息作为词向量

## 自然语言理解NLU
 语义表示
1.	领域[垂类](domain)：领域是指同一类型的数据或者资源，以及围绕这些数据或资源提供的服务，比如天气、音乐等，也习惯叫做垂类。
2.	意图(intent)：意图是指对于领域数据的操作，一般以动宾短语来命名，比如询问天气、查找音乐。
3.	词槽(slot)：词槽用来存放领域的属性，比如天气领域的日期、天气，音乐领域的歌手、歌曲名等。
   
## NLU算法实现
1. 意图识别(Intent Detection)  
**离散词向量表示**  
词集模型(Set of Word)
- One-Hot encoding
- 统计各词在句子中是否出现  
词袋模型(Bag of Word)  
- 统计各词在句子中出现的次数  
Bi-gram、N-gram  
TF-IDF  
统计各词在文档中的TF-IDF值(词袋模型+IDF值)  
共现矩阵  
**分布式词向量表示**
- Word Embedding词嵌入(word2vec、Glove) ---> 词语相似度、关系、映射；
- 深度学习：句子表示(RNN、CNN)；
2.	槽位提取
- 规则匹配方法
- 传统机器学习算法
- 深度学习算法
模型评估
- 准确率(accuracy)=(TP+TN)/(TP+TN+FP+FN)=70%
- 精确率(precision)=TP/(TP+FP)=80%
- 召回率(recall)=TP/(TP+FN)=66.7%
- F1值(精确率和召回率的调和均值)=2PR/(P+R)=72.7%
- ROC curve = TPR/FPR, TPR = TP/(TP + FN), FPR = FP/(FP + TN)
- AUC = S(ROC-xaxis)
